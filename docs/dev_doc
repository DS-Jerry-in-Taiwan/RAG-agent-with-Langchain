# RAG 系統開發階段規劃與 Checklist

參考 [LangChain RAG 官方文件](https://docs.langchain.com/oss/python/langchain/rag) 主流流程，將開發分為五大階段，每階段附上 Checklist，方便團隊追蹤進度。

---

## 1. 模型初始化階段

**目標**：串接第三方 LLM API，建立生成模型物件。

**Checklist**
- [ ] 設定 `.env` 並安全管理 API Key
- [ ] 串接 OpenAI（或其他 LLM）API
- [ ] 初始化 ChatOpenAI 或相關模型物件
- [ ] 驗證模型物件可正常回應

---

## 2. 文件載入階段

**目標**：將原始知識庫資料（PDF、TXT、網頁等）載入至系統。

## 文件載入階段開發步驟

1. **選擇合適的 Document Loader**
   - 根據資料格式選擇載入器：  
     - PDF：`PyPDFLoader`
     - 純文字：`TextLoader`
     - 網頁：`WebBaseLoader`
   - 安裝相關套件（如 `pip install langchain`、`pip install unstructured`）

2. **實作文件載入程式**
   - 初始化載入器，讀取指定路徑的文件
   - 支援多檔案批次載入（可用迴圈或 glob）

3. **支援多種資料格式**
   - 擴充載入器，讓系統可處理 PDF、TXT、網頁等多種格式
   - 根據檔案類型自動選擇對應載入器

4. **驗證載入結果正確**
   - 檢查載入後的文件內容與結構
   - 撰寫測試程式，確保載入器穩定運作
   - 針對不同格式進行內容比對與例外處理

---

> 建議每完成一項步驟，進行單元測試與結果驗收，確保資料載入流程正確且穩定。

**Checklist**
- [X] 選擇合適的 Document Loader（如 PyPDFLoader、TextLoader）
- [X] 實作文件載入程式
- [X] 支援多種資料格式
- [X] 驗證載入結果正確

---

## 3. 文件分段階段

**目標**：將長文件切分為適合向量化的小段落。

1. **選擇分段工具**
   - 使用主流的 `RecursiveCharacterTextSplitter`（LangChain 提供）。

2. **設定分段參數**
   - 設定 `chunk_size`（每段最大字數）與 `chunk_overlap`（段落重疊字數），例如：
     ```python
     splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
     ```

3. **實作分段流程**
   - 調用分段工具，將載入的 documents 切分為多個小段落：
     ```python
     split_docs = splitter.split_documents(documents)
     ```

4. **驗證分段結果合理**
   - 檢查分段後的數量與內容，確保每段都有內容且分段邏輯正確。
   - 範例：
     ```python
     print(f"分段後共 {len(split_docs)} 段")
     for i, doc in enumerate(split_docs[:3]):
         print(f"第 {i+1} 段內容：{doc.page_content[:100]}...")
     for doc in split_docs:
         assert doc.page_content, "分段內容為空"
     ```

---

**Checklist**
- [X] 選擇分段工具（如 RecursiveCharacterTextSplitter）
- [X] 設定分段參數（chunk_size, chunk_overlap）
- [X] 實作分段流程
- [X] 驗證分段結果合理

---

## 4. 文件向量化階段

**目標**：將每個段落轉換為向量，保留語意資訊。

## 文件向量化階段開發步驟

1. **選擇嵌入模型**
   - 根據需求選擇主流嵌入模型，例如：
     - OpenAIEmbeddings（需 OpenAI API Key）
     - Sentence Transformers（本地模型）

2. **實作向量化流程**
   - 初始化嵌入模型
   - 將分段後的文件（split_docs）轉換為向量
   - 範例：
     ```python
     from langchain_openai import OpenAIEmbeddings
     embeddings = OpenAIEmbeddings()
     vectors = embeddings.embed_documents([doc.page_content for doc in split_docs])
     ```

3. **驗證向量生成結果**
   - 檢查每個段落是否成功生成向量
   - 比對向量維度與內容是否合理
   - 範例：
     ```python
     print(f"共生成 {len(vectors)} 筆向量")
     print(f"第一筆向量維度：{len(vectors[0])}")
     ```

4. **測試嵌入模型效能**
   - 測試嵌入速度與資源消耗
   - 針對不同資料量進行效能評估

---

**Checklist**
- [X] 選擇嵌入模型（如 OpenAIEmbeddings、Sentence Transformers）
- [X] 實作向量化流程
- [X] 驗證向量生成結果
- [X] 測試嵌入模型效能

---

## 5. 向量資料庫建置與儲存階段

**目標**：將向量資料存入向量資料庫，支援高效檢索。

**Checklist**
- [ ] 選擇向量資料庫（如 FAISS、Chroma、Pinecone）
- [ ] 實作資料庫建置與儲存流程
- [ ] 驗證資料庫查詢功能
- [ ] 測試資料庫效能與穩定性

---

## 6. 檢索與生成整合階段（RAG Pipeline）

**目標**：串接檢索與生成流程，實現端到端問答。

**Checklist**
- [ ] 串接 Retriever 與 LLM 生成模組
- [ ] 實作 RAG Chain 主流程
- [ ] 測試問答效果
- [ ] 優化檢索與生成策略

---

## 7. Chatbot 介面設計階段

**目標**：提供 CLI、Web 或 API 互動介面。

**Checklist**
- [ ] 選擇介面類型（CLI/Web/API）
- [ ] 實作基本互動功能
- [ ] 測試使用者體驗
- [ ] 完善錯誤處理與提示

---

## 8. 測試與優化階段

**目標**：確保各模組穩定運作，持續優化系統效能。

**Checklist**
- [ ] 撰寫單元測試
- [ ] 進行整合測試
- [ ] 優化檢索與生成效果
- [ ] 定期回顧與重構程式碼

---

> 建議每完成一階段，團隊進行回顧與驗收，確保品質與進度。